{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "b37f1c6b",
   "metadata": {},
   "source": [
    "# Convolutional Neural Networks A "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b13a31f8",
   "metadata": {},
   "source": [
    "## DEEP COMPUTER VISION"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e8b1f6b9",
   "metadata": {},
   "source": [
    "in this guide we will learn how to perform image classification and object detection using deep computer vision with the convolutional neural networkd.                                                                                                 \n",
    " we will be to classify and detect images or specific objects from within the images. we will be using images data as our features and label for those images as our label or output.                                                                      \n",
    " the following concepts are important.                                                                                          \n",
    " . Image  data                                                                                                                 \n",
    " .Convolutional Layer                                                                                                           \n",
    " . Pooling Layer.                                                                                                               \n",
    " . CNN Architectures                                                                                                           \n",
    " #### the Major differnce in this type of neural networks are the layers that make them up."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "81077c64",
   "metadata": {},
   "source": [
    "### Image Data\n",
    "we are going to deal with 3Dimensions  the tree dimensions are as follows:                                                         . Image height                                                                                                                 . Image Width                                                                                                                   . Color Channels -  the number of chanels represents the depth of an image and coorelates to the colors used. example an image with three channels is likely made up of rgb(red, gree, blue) pixels. So For Each Pixel we have three numeric Values in range 0 - 255 that defines its color. for an image of color depth 1 we would likely have a greyscale image with one value defining each pixel, again in the range of 0 - 255."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "39303e7c",
   "metadata": {},
   "source": [
    "## Convolutional Neural Network\n",
    "note: i will use the tearm convnet and convolutional neural network interchangably"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fe55de18",
   "metadata": {},
   "source": [
    "this type of neural network is made up of many convolutional layers. they are different from the dense layers. the goal of this layers is to find pattens from the images that can be used to classify the image or parts of it.\n",
    "    The fundamental differnce betwen  a dense layer and a convolutional layer is that dense layers detect patterns globally while convolutional layer detects patterns locally. when we have a densly connected layer each node in that layer sees all the data from the previous layer. this means that this layer is looking at all of the information and is only capable of analyzing the data in a global capacity. \n",
    "        our convolutional layer however will not be densly connectd, this means it can detect local patterns using part of input data to that layer"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b2f03da6",
   "metadata": {},
   "source": [
    "#### a dense neural network learns patterns that are in one specific area of an image while convolutional Neural network learns  patterns in any area of the image regardeles when the image is fliped it will still locate the patterns."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f66e538b",
   "metadata": {},
   "source": [
    "# The Convolutional Layer"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8cf1654b",
   "metadata": {},
   "source": [
    " NOW creating our first Convent for this we will get famillier with CNN architectures."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "652c7dcb",
   "metadata": {},
   "source": [
    "### Dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "32e13f2c",
   "metadata": {},
   "source": [
    "the problem here isn to clasify 10 different everdays objects. the data set we will use is built into tensorflow and called Cifar Image dataset it contains 60,000 32 x32 color images with 6000 images of each class.\n",
    "     this are the labels:\n",
    "         .Airplane, Automobile, Bird,Cat, Deer, Dog, Frog, Horse, Ship, Truck"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "74f53ed2",
   "metadata": {},
   "source": [
    "## Loading the Data set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "c4d75b9a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow.keras import datasets, layers, models\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "97162133",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load AND SPLIT DATASET\n",
    "(train_images, train_labels), (test_images, test_labels) = datasets.cifar10.load_data()\n",
    "#Normalize pixel values to be bewteen 0 and 1\n",
    "train_images, test_images = train_images/ 255.0, test_images / 255.0\n",
    "\n",
    "class_names = ['airplane','automobile','bird','cat','deer','dog','frog','horse','ship','truck']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "63d9b28c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# lets look at one of the image\n",
    "IMG_INDEX = 1 # change this to look at other images\n",
    "\n",
    "plt.imshow(train_images[IMG_INDEX], cmap=plt.cm.binary)\n",
    "plt.xlabel(class_names[train_labels[IMG_INDEX][0]])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "16351289",
   "metadata": {},
   "source": [
    "## CNN Architecture\n",
    "this is a stack of Conv2D and MaxPooling2D layers followed by a dense connected layers.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8774483d",
   "metadata": {},
   "source": [
    "the Idea is to stack convolutional and maxPooling layers to extract the features from the images. this features are flattend and fed to a densly connected layers that determine the class of an image based on the presence of features.                \n",
    "### Now lets start building the Convolutional Base"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "d8f7e872",
   "metadata": {},
   "outputs": [],
   "source": [
    "model= models.Sequential()\n",
    "model.add(layers.Conv2D(32,(3,3), activation='relu', input_shape=(32,32,3)))\n",
    "model.add(layers.MaxPooling2D((2,2)))\n",
    "model.add(layers.Conv2D(64,(3,3),activation='relu'))\n",
    "model.add(layers.MaxPooling2D((2,2)))\n",
    "model.add(layers.Conv2D(64, (3,3),activation= 'relu'))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "90c1047f",
   "metadata": {},
   "source": [
    "### Layer 1\n",
    "THIS input will be 32, 32, 3 and we will process 32 filter size 3x3 over our input data. we will apply the activation function relu to the output of each convolution operation."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "57397d05",
   "metadata": {},
   "source": [
    "### Layer 2\n",
    "this will perform the max pooling operation using 2 x 2 samples and stride of 2"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e8a4e7ed",
   "metadata": {},
   "source": [
    "### Other Layers\n",
    "The next set of layers do very similar things but take as input the feature map from the previous layer. they also increase the frequency of filters from 32 to 64. \n",
    "        WE Can do this as our data shrinks in spacial dimensions as it passed through the layers, meaning we can afford(computationally) to add more depth."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "fa5e31aa",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " conv2d (Conv2D)             (None, 30, 30, 32)        896       \n",
      "                                                                 \n",
      " max_pooling2d (MaxPooling2  (None, 15, 15, 32)        0         \n",
      " D)                                                              \n",
      "                                                                 \n",
      " conv2d_1 (Conv2D)           (None, 13, 13, 64)        18496     \n",
      "                                                                 \n",
      " max_pooling2d_1 (MaxPoolin  (None, 6, 6, 64)          0         \n",
      " g2D)                                                            \n",
      "                                                                 \n",
      " conv2d_2 (Conv2D)           (None, 4, 4, 64)          36928     \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 56320 (220.00 KB)\n",
      "Trainable params: 56320 (220.00 KB)\n",
      "Non-trainable params: 0 (0.00 Byte)\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "# model summary\n",
    "model.summary() # lets have a look at our model so far"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9aeebbb0",
   "metadata": {},
   "source": [
    "## Adding Dense Layers"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "37d7bda9",
   "metadata": {},
   "source": [
    "now we need to take these extracted features and add a way to classify them. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "708648d2",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.add(layers.Flatten())\n",
    "model.add(layers.Dense(64,activation = 'relu'))\n",
    "model.add(layers.Dense(10))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "27e050e6",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " conv2d (Conv2D)             (None, 30, 30, 32)        896       \n",
      "                                                                 \n",
      " max_pooling2d (MaxPooling2  (None, 15, 15, 32)        0         \n",
      " D)                                                              \n",
      "                                                                 \n",
      " conv2d_1 (Conv2D)           (None, 13, 13, 64)        18496     \n",
      "                                                                 \n",
      " max_pooling2d_1 (MaxPoolin  (None, 6, 6, 64)          0         \n",
      " g2D)                                                            \n",
      "                                                                 \n",
      " conv2d_2 (Conv2D)           (None, 4, 4, 64)          36928     \n",
      "                                                                 \n",
      " flatten (Flatten)           (None, 1024)              0         \n",
      "                                                                 \n",
      " dense (Dense)               (None, 64)                65600     \n",
      "                                                                 \n",
      " dense_1 (Dense)             (None, 10)                650       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 122570 (478.79 KB)\n",
      "Trainable params: 122570 (478.79 KB)\n",
      "Non-trainable params: 0 (0.00 Byte)\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e5f21177",
   "metadata": {},
   "source": [
    "## Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "6f8d9eeb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/5\n",
      "1563/1563 [==============================] - 117s 55ms/step - loss: 1.5431 - accuracy: 0.4376 - val_loss: 1.2656 - val_accuracy: 0.5401\n",
      "Epoch 2/5\n",
      "1563/1563 [==============================] - 70s 45ms/step - loss: 1.1868 - accuracy: 0.5786 - val_loss: 1.1217 - val_accuracy: 0.5986\n",
      "Epoch 3/5\n",
      "1563/1563 [==============================] - 71s 45ms/step - loss: 1.0302 - accuracy: 0.6393 - val_loss: 1.0058 - val_accuracy: 0.6407\n",
      "Epoch 4/5\n",
      "1563/1563 [==============================] - 71s 45ms/step - loss: 0.9319 - accuracy: 0.6726 - val_loss: 0.9498 - val_accuracy: 0.6665\n",
      "Epoch 5/5\n",
      "1563/1563 [==============================] - 71s 46ms/step - loss: 0.8634 - accuracy: 0.6958 - val_loss: 0.9286 - val_accuracy: 0.6786\n"
     ]
    }
   ],
   "source": [
    "#we will train and compile the model using the recommended hyper paramaters from tensorflow NB this will take much longer\n",
    "model.compile(optimizer='adam',\n",
    "             loss=tf.keras.losses.SparseCategoricalCrossentropy(from_logits = True),\n",
    "             metrics= ['accuracy'])\n",
    "history = model.fit(train_images, train_labels, epochs = 5,\n",
    "                   validation_data=(test_images,test_labels))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "99a3d2ce",
   "metadata": {},
   "source": [
    "# Evaluating the Model\n",
    "we can determine how well the model performed by looking at its performance on the test data set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "456b0d01",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "313/313 - 5s - loss: 0.9286 - accuracy: 0.6786 - 5s/epoch - 15ms/step\n",
      "0.678600013256073\n"
     ]
    }
   ],
   "source": [
    "test_loss, test_acc = model.evaluate(test_images, test_labels, verbose=2)\n",
    "print(test_acc)\n",
    "# you should be getting the accuracy of about 70 %  for this model of computer vision"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "981d5f5c",
   "metadata": {},
   "source": [
    "# WORKING with small Datasets\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4377ac76",
   "metadata": {},
   "source": [
    "in this situationwhere you do not have millions of data  to train a CNN from scratch that pertforms well. this is why we will learn about a few techniques we can use to train CNN on small datasets or just a few thousands"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dae52f60",
   "metadata": {},
   "source": [
    "# Data Augmentation"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d850e5ab",
   "metadata": {},
   "source": [
    "to avoid overfitting a model and create a larger data set from a smaller one we can use a technique called data augmentation. this is simplly performining random transformation on our images so that our model can generalize better this transormations can be things like compressions, rotations, stretches and even color changers.\n",
    "### this is done with Keras"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6577c809",
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
